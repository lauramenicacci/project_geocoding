{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f28174",
   "metadata": {},
   "source": [
    "### Importing data: countries' position and import/export flows \n",
    "We start from downloading the data from the [Eurostat transport database](https://ec.europa.eu/eurostat/web/transport/data/database). We are interested in the positions of the countries, thus latitude and longitude, so that we can use this information to plot the countries of interest into a world map. \n",
    "Then, we proceed with uploading the dataset containing the information of import and export activities and flows ('complete_dataset'). \n",
    "We update the position dataset with only the countries contained in the import/export dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e05ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "<<<<<<< HEAD\n",
    "# Download the csv with every country and the position (latitude and longitude)\n",
    "=======\n",
    "#Download the csv with countries and positions (latitude and longitude)\n",
    ">>>>>>> 6e40c3fe69dbfdb78f68303afc83ebfd51df0415\n",
    "url = 'https://developers.google.com/public-data/docs/canonical/countries_csv'\n",
    "html = requests.get(url).content\n",
    "df_list = pd.read_html(html)\n",
    "df_position = df_list[-1]\n",
    "<<<<<<< HEAD\n",
    "\n",
    "#read the c\n",
    "=======\n",
    "#import the complete dataset\n",
    ">>>>>>> 6e40c3fe69dbfdb78f68303afc83ebfd51df0415\n",
    "complete_dataset = pd.read_csv('official_dataset.csv')\n",
    "\n",
    "#create list \"l\" of countries : from position dataset (df_position), select and append only the countries that are also present\n",
    "# in the official_dataset (Only EU countries)\n",
    "l = []\n",
    "for i in list(df_position['name']):\n",
    "    l.append(i in list(set(complete_dataset['REPORTER'])))\n",
    "print(l)\n",
    "\n",
    "# update position dataframe (filtered in the step before)\n",
    "df_position = df_position[l]\n",
    "#export dataset\n",
    "df_position.to_csv('position_countries.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4aa3b6",
   "metadata": {},
   "source": [
    "### Clean and merge datasets\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908306c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import add_lat_lon_3\n",
    "import os\n",
    "\n",
    "def merge_database(complete_df, already_merged = []):\n",
    "    '''\n",
    "    Return the joined dataset and a list of the name of the file already merged.\n",
    "\n",
    "    If already merged is not passed, it is considered empty.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    complete_dataset: pandas DataFrame that you want to extend.\n",
    "    '''\n",
    "    l = []\n",
    "    for dir in  os.listdir(str(os.getcwd()) + '/dataset_project_DSA'):\n",
    "        if dir[0:4] == 'data' and dir not in already_merged:\n",
    "            PATH = str(os.getcwd() + '/dataset_project_DSA/'+ dir +'/DS-1262527_1_Data.csv')\n",
    "            data = pd.read_csv(PATH)\n",
    "            data = add_lat_lon_3.clean_df(data)\n",
    "            pos_countries = pd.read_csv(str(os.getcwd() + '/dataset_project_DSA/position_countries.csv'))\n",
    "            data = add_lat_lon_3.add_lat_lon(data, pos_countries)\n",
    "            l.append(data)\n",
    "            already_merged.append(dir)\n",
    "    datas = pd.concat(l)\n",
    "    return datas, already_merged\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tup = merge_database([])\n",
    "    tup[0].to_csv('./official_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20529341",
   "metadata": {},
   "source": [
    "## Adding latitude and longitude information\n",
    "We proceed with cleaning some countries' names and creating a function that appends latitute and longitude of each country name contained in the main dataset, in order to have one single csv that can be used as a proper base for analysis and plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf768980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_df(df):\n",
    "    '''\n",
    "    Function that clean the name of the counties in the dataset\n",
    "    (e.g.  from 'Belgium (incl. Luxembourg LU -> 1998)' to 'Belgium')\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas dataFrame that is it necessary to be clean\n",
    "\n",
    "    '''\n",
    "    drop_df = df.loc[df['REPORTER'] == 'Czechia']\n",
    "    df = df.drop(drop_df.index)\n",
    "    df['REPORTER'] = df['REPORTER'].replace({'Belgium (incl. Luxembourg \\'LU\\' -> 1998)':'Belgium'})\n",
    "    df['REPORTER'] = df['REPORTER'].replace({'Germany (incl. German Democratic Republic \\'DD\\' from 1991)':'Germany'})\n",
    "    df['REPORTER'] = df['REPORTER'].replace({'Ireland (Eire)':'Ireland'})\n",
    "    df['REPORTER'] = df['REPORTER'].replace({'Spain (incl. Canary Islands \\'XB\\' from 1997)':'Spain'})\n",
    "    df['REPORTER'] = df['REPORTER'].replace({'France (incl. Saint Barth�lemy \\'BL\\' -> 2012; incl. French Guiana \\'GF\\', Guadeloupe \\'GP\\', Martinique \\'MQ\\', R�union \\'RE\\' from 1997; incl. Mayotte \\'YT\\' from 2014)':'France'})\n",
    "    df['REPORTER'] = df['REPORTER'].replace({'Italy (incl. San Marino \\'SM\\' -> 1993)':'Italy'})\n",
    "    return df\n",
    "\n",
    "def add_lat_lon(df, pos_countries):\n",
    "    '''\n",
    "    It add the latitude and longitude to the main dataset, so now it is ready to\n",
    "    be passed to plotly\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: main pandas dataFrame\n",
    "    pos_countries: pandas DataFrame with the latitude and longitude\n",
    "    '''\n",
    "    d_lat = dict(zip(pos_countries['name'], pos_countries['latitude']))\n",
    "    d_long = dict(zip(pos_countries['name'], pos_countries['longitude']))\n",
    "    lat = []\n",
    "    long = []\n",
    "    for index, row in df.iterrows(): #there are only 500, that's way I iterate over the rows\n",
    "        lat.append(d_lat[row['REPORTER']])\n",
    "        long.append(d_long[row['REPORTER']])\n",
    "    df['Latitude'] = lat\n",
    "    df['Longitude'] = long\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = pd.read_csv('dataset_project_DSA/dataset_india_export/DS-1262527_1_Data.csv')\n",
    "    pos_countries = pd.read_csv('position_countries.csv')\n",
    "\n",
    "    print(add_lat_lon(clean_df(df), pos_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef1caa1",
   "metadata": {},
   "source": [
    "### Mapping Imports and Exports\n",
    "As the final step, we plot the import and exports data.\n",
    "Our final representation has values of imports and exports contained inside the bubbles, that can be interactively clicked. It is also possible to select single countries to further analyse the relationship with the European Union. \n",
    "A slider has been added to make it easier investigating how the flows changed over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "official_df = pd.read_csv('..\\official_dataset.csv')\n",
    "lat = official_df['Latitude'].unique()\n",
    "lon = official_df['Longitude'].unique()\n",
    "\n",
    "#subset dataset for import data\n",
    "official_df_imp = official_df.loc[official_df['FLOW'] == 'IMPORT']\n",
    "official_df_imp['Value'] = official_df_imp['Value'].str.replace(' ','').replace(':','0')\n",
    "official_df_imp['Value'] = official_df_imp['Value'].astype(float)\n",
    "\n",
    "#prepare dynamic map which shows evolution of imports over a two-year time\n",
    "#the bubbles represent the size of imports of each EU countries from BRICS and USA\n",
    "#it is possible to filter by partner and select the period to visualize\n",
    "\n",
    "fig = px.scatter_geo(official_df_imp,\n",
    "                    lat = 'Latitude',\n",
    "                    lon = 'Longitude',\n",
    "                    animation_frame = 'PERIOD',\n",
    "                    size_max = 55,\n",
    "                    hover_name = 'REPORTER',\n",
    "                    size = 'Value',\n",
    "                    color = 'PARTNER',\n",
    "                    title=\"IMPORTS of EU countries from BRICS and USA\")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", showcountries = True)\n",
    "#plot map\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#plot dynamic map which shows evolution of exports over a two-year time\n",
    "#the bubbles represent the size of exports from each EU countries to BRICS and USA\n",
    "#it is possible to filter by partner and select the period to visualize\n",
    "\n",
    "official_df_exp = official_df.loc[official_df['FLOW'] == 'EXPORT']\n",
    "official_df_exp['Value'] = official_df_exp['Value'].str.replace(' ','').replace(':','0')\n",
    "official_df_exp['Value'] = official_df_exp['Value'].astype(float)\n",
    "\n",
    "\n",
    "fig = px.scatter_geo(official_df_exp,\n",
    "                    lat = 'Latitude',\n",
    "                    lon = 'Longitude',\n",
    "                    animation_frame = 'PERIOD',\n",
    "                    size_max = 55,\n",
    "                    hover_name = 'REPORTER',\n",
    "                    size = 'Value',\n",
    "                    color = 'PARTNER',\n",
    "                    title=\"EXPORTS from EU countries to BRICS and USA\")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", showcountries = True)\n",
    "#plot map\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44454e54",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "The data observed are quite interesting, especially when looking at the change over time. It is possible to notice a significant spike in flows when going from 2020 to 2021."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
